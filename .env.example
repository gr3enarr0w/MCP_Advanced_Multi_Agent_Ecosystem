# ==========================================
# Phase 1 Environment Configuration Example
# ==========================================
# Copy this file to .env.external-mcps and update with your actual values
# DO NOT commit actual API keys to version control

# ==========================================
# External MCP Server Configuration
# ==========================================
# These paths are used by agent-swarm internally
# Source this file or add to ~/.mcp/roo-mcp.env

# Context7 Configuration (TypeScript/Node)
CONTEXT7_MCP_CMD=node
CONTEXT7_MCP_ARGS=/Users/ceverson/MCP_Advanced_Multi_Agent_Ecosystem/src/mcp-servers/external/context7/dist/index.js
# CONTEXT7_API_KEY=your-upstash-api-key-here
# CONTEXT7_PROJECT=your-project-id-here

# MCP Code Checker Configuration (Python)
# Installed via pip, available as 'mcp-code-checker' command
MCP_CODE_CHECKER_CMD=mcp-code-checker
MCP_CODE_CHECKER_PROJECT_DIR=${PWD}
# Optionally specify Python executable
# MCP_CODE_CHECKER_PYTHON=/path/to/python3

# ==========================================
# LLM Configuration (Phase 1)
# ==========================================
# LLM mode: hybrid, local, or cloud
LLM_MODE=hybrid

# Local LLM Provider Configuration
LLM_LOCAL_PROVIDER=ollama
LLM_LOCAL_MODEL=llama2:70b
LLM_LOCAL_URL=http://localhost:11434

# Cloud LLM Provider Configuration
LLM_CLOUD_PROVIDER=perplexity
LLM_CLOUD_MODEL=sonar-pro

# LLM Fallback Configuration
LLM_FALLBACK_ENABLED=true
LLM_FALLBACK_ORDER=local,cloud
LLM_COMPLEXITY_THRESHOLD=0.6
LLM_COST_TRACKING=true

# ==========================================
# Search API Keys (Phase 1)
# ==========================================
# Tavily API (Primary) - REQUIRED
# Get from: https://tavily.com/dashboard
TAVILY_API_KEY=tvly_your_actual_tavily_api_key_here

# Perplexity API - REQUIRED
# Get from: https://www.perplexity.ai/settings/api
PERPLEXITY_API_KEY=pplx_your_actual_perplexity_api_key_here

# Brave API - OPTIONAL
# Get from: https://brave.com/search/api/
BRAVE_API_KEY=BSyour_actual_brave_api_key_here

# DuckDuckGo (Free - no key required)
# No API key needed for DuckDuckGo

# ==========================================
# Search Provider Configuration (Phase 1)
# ==========================================
# Comma-separated list of search providers to use
SEARCH_PROVIDERS=tavily,perplexity,brave,duckduckgo

# Enable parallel search across multiple providers
SEARCH_PARALLEL_ENABLED=true

# Provider priority (lower number = higher priority)
SEARCH_TAVILY_PRIORITY=1
SEARCH_PERPLEXITY_PRIORITY=2
SEARCH_BRAVE_PRIORITY=3
SEARCH_DUCKDUCKGO_PRIORITY=4

# Search limits and timeouts
SEARCH_MAX_RESULTS=10
SEARCH_TIMEOUT=30000

# ==========================================
# Research Configuration (Phase 1)
# ==========================================
# Maximum research iterations
RESEARCH_MAX_ITERATIONS=5

# Quality threshold for research results
RESEARCH_QUALITY_THRESHOLD=0.75

# Citation style for research outputs
RESEARCH_CITATION_STYLE=apa

# Enable streaming for research results
RESEARCH_ENABLE_STREAMING=true

# ==========================================
# Example Configurations for Different Use Cases
# ==========================================

# --- Development Setup Example ---
# Uncomment and modify for development environment
# LLM_MODE=local
# LLM_LOCAL_MODEL=llama2:7b
# SEARCH_PROVIDERS=duckduckgo
# SEARCH_PARALLEL_ENABLED=false

# --- Production Setup Example ---
# Uncomment and modify for production environment
# LLM_MODE=hybrid
# LLM_LOCAL_MODEL=llama2:70b
# LLM_CLOUD_MODEL=sonar-pro
# SEARCH_PROVIDERS=tavily,perplexity,brave,duckduckgo
# SEARCH_PARALLEL_ENABLED=true
# LLM_COST_TRACKING=true

# --- Cost-Optimized Setup Example ---
# Uncomment and modify to minimize costs
# LLM_MODE=local
# LLM_FALLBACK_ENABLED=false
# SEARCH_PROVIDERS=duckduckgo,tavily
# SEARCH_TAVILY_PRIORITY=2

# ==========================================
# Security and Debug Options
# ==========================================
# Enable debug logging (uncomment for troubleshooting)
# DEBUG=true
# LOG_LEVEL=debug

# ==========================================
# Setup Instructions
# ==========================================
# 1. Copy this file to .env.external-mcps
# 2. Replace placeholder API keys with actual values
# 3. Adjust configuration based on your needs
# 4. Run validation: ./scripts/validate-env.sh
# 5. Source the file: source .env.external-mcps
#
# For detailed instructions, see: docs/llm-search-config.md